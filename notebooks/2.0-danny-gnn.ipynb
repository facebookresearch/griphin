{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 1, 2, 3])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = torch.tensor([0, 1, 0, 2, 1, 2, 3, 3])\n",
    "m1 = torch.tensor([True, True, False, True, False, False, True, False])\n",
    "m2 = ~ m1\n",
    "t[m2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([3, 1])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.nonzero(as_tuple=False).view(-1)[[2,1]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([613393, 581754,  29689,  ..., 159676, 399976, 440506],\n        dtype=torch.int32),\n tensor([0, 0, 0,  ..., 0, 0, 0], dtype=torch.int8),\n tensor([6.8911e-06, 1.7770e-03, 5.6566e-05,  ..., 5.8274e-05, 1.4357e-05,\n         2.1618e-05]))"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = '/home/gangda/workspace/graph_engine/temp'\n",
    "PREP_DIR = '/home/gangda/workspace/graph_engine/data/ogbn-products-p4'\n",
    "\n",
    "ppr = torch.load(DATA_DIR + '/data.pt')\n",
    "ppr[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[ 0.0319, -0.1959,  0.0520,  ...,  0.0767, -0.3930, -0.0648],\n         [-0.0241,  0.6303,  1.0606,  ..., -1.6875,  3.5867,  0.8182],\n         [ 0.3327, -0.5586, -0.2886,  ..., -0.3716,  0.2521,  0.0415],\n         ...,\n         [ 0.1066,  0.2655, -0.0057,  ...,  1.0867,  0.0759, -1.1737],\n         [ 0.2497, -0.2574,  0.4123,  ...,  1.5466,  1.0310, -0.2966],\n         [ 0.7175, -0.2393,  0.0443,  ..., -1.0132, -0.4141, -0.0823]]),\n tensor([[      0,       0,       0,  ..., 2449028, 2449028, 2449028],\n         [    384,    2412,    7554,  ..., 1787657, 1864057, 2430488]]))"
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ogb.nodeproppred import DglNodePropPredDataset\n",
    "\n",
    "og, y = DglNodePropPredDataset(name='ogbn-products', root='/data/gangda/dgl')[0]\n",
    "X = og.ndata['feat']\n",
    "edge_index = torch.load(PREP_DIR + '/dgl_edge_index.pt')\n",
    "X, edge_index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([     0, 278804, 455672, 497655, 452891, 444152, 288305,  93215, 195938,\n         125016, 486015, 530822, 578054, 481287, 473931, 486758, 420232, 587793,\n         505595, 474696, 292000, 450011, 259331, 572588, 271538, 437809, 432737,\n         164038, 398473, 159000, 425421, 453506, 165863, 574107, 570637,  89482,\n         518980, 541320, 476820, 514113, 518844, 215361,  15741, 594026, 565901,\n         139082, 466278, 409354, 257575, 147013, 587127, 466706, 431252,  49016,\n         609684, 133808, 194663, 579937, 348718, 434766, 552249, 622466,  81609,\n         474646, 474723, 506845, 479771, 254098, 573020, 122724, 538145, 485431,\n         535468, 512714, 547847, 611277, 578137, 277645, 471651, 240417,  76635,\n         616164, 581754, 593143, 576630,  32276, 585355, 537633, 374098, 434405,\n         394040, 409727, 349741, 390371, 339188, 136042, 432869, 517115, 446749,\n         464813], dtype=torch.int32),\n tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0], dtype=torch.int8))"
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v, i = torch.sort(ppr[0][2], descending=True)\n",
    "top_100_index = i[:100]\n",
    "local_id, shard_id = ppr[0][0][top_100_index], ppr[0][1][top_100_index]\n",
    "local_id, shard_id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([1578341,  580537, 1578356,  ..., 1969840, 2255870,  320072]),\n tensor([1231032, 2291684, 1306048,  ...,   10705,   51625,  930216]),\n tensor([ 920623, 1636464,  533610,  ..., 1957407, 1981728,  691187]),\n tensor([ 259846, 2060628, 2032898,  ...,  511433, 1681439, 1681440])]"
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parts = torch.load(PREP_DIR + '/metis_partitions.pt')\n",
    "num_parts = len(parts)\n",
    "\n",
    "part_core_global_ids = []\n",
    "for i in range(num_parts):\n",
    "    part = parts[i]\n",
    "    core_mask = part.ndata['inner_node'].type(torch.bool)\n",
    "    part_global_id = part.ndata['orig_id']\n",
    "    part_core_global_ids.append(part_global_id[core_mask])\n",
    "\n",
    "part_core_global_ids"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1578341, 1040833,  196128,  232835,  218061, 2028409, 1358269, 1499731,\n         880916, 1853590,   82307, 1888491,   39785,   80922,  215340,   83086,\n         174582,   47004,  111744, 2301674,  733033,   95345, 1004785,  166341,\n        1079953,   62190,  120665,  519920, 2337523, 1652673,  171130,  108086,\n        1673204,  167416, 2385923, 1508538,  133438,  146506,  101068,   22019,\n           5807, 1186379, 1541565,  141295, 1914750, 1848082,  106002,  261337,\n        1001437, 1681058,   46790,  106128, 2032080, 1465257,  328131,  410859,\n        1120712, 1882334, 1215430,  119741,   26137,   35549, 1527459,  107237,\n          98555,  191855,  189967,  976753,  166250,  397914,   26652,  279386,\n        1942497,  155362,   13538,  161245,   39748, 1038434,  107201,  951020,\n        1519425,  128681,   41001,  305715, 2198315,  532943,   47469,   26696,\n        1261833, 2030709,  180796,   70648,  829119,  119226, 1236241,  414299,\n         177042,  145002,  198189,  202560])"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_id_mapping = torch.load(PREP_DIR + '/local_id_mapping.pt')\n",
    "shard_id_mapping = torch.load(PREP_DIR + '/shard_id_mapping.pt')\n",
    "\n",
    "def get_global_id(local_ids_, shard_ids_):\n",
    "    local_ids_ = local_ids_.to(torch.long)\n",
    "    global_ids = torch.empty_like(local_ids_)\n",
    "    for j in range(num_parts):\n",
    "        mask = shard_ids_ == j\n",
    "        if mask.sum() == 0: continue\n",
    "        global_ids[mask] = part_core_global_ids[j][local_ids_[mask]]\n",
    "    return global_ids\n",
    "\n",
    "get_global_id(local_id, shard_id)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import is_undirected, contains_self_loops, add_remaining_self_loops\n",
    "\n",
    "data = Data(X, add_remaining_self_loops(edge_index)[0])\n",
    "X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[3161, 100], edge_index=[2, 63482], y=[32, 1], ego_idx=[32])"
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "K = 100\n",
    "batch_index = torch.arange(32)\n",
    "rank = 0\n",
    "dist_subgraph = lambda x: subgraph(x, edge_index)[0]\n",
    "\n",
    "def convert_batch_data(ppr_res, batch_index, K, dist_subgraph):\n",
    "    batch_size = batch_index.shape[0]\n",
    "\n",
    "    batch_local_ids = [batch_index]\n",
    "    batch_shard_ids = [torch.full((batch_size,), rank)]\n",
    "    for i in range(len(ppr_res)):\n",
    "        val, idx = torch.sort(ppr_res[i][2], descending=True)\n",
    "        top_k_index = idx[:K]\n",
    "        batch_local_ids.append(ppr_res[i][0][top_k_index])\n",
    "        batch_shard_ids.append(ppr_res[i][1][top_k_index])\n",
    "\n",
    "    batch_local_ids, batch_shard_ids = torch.cat(batch_local_ids), torch.cat(batch_shard_ids)\n",
    "    subset = get_global_id(batch_local_ids, batch_shard_ids)\n",
    "    batch_node_global_id = subset[:batch_size]\n",
    "\n",
    "    unique_subset, inv = subset.unique(return_inverse=True)\n",
    "    sub_edge_index = dist_subgraph(unique_subset)\n",
    "    local_e = sub_edge_index.unique(return_inverse=True)[1]\n",
    "\n",
    "    return Data(X[unique_subset], local_e, y=y[batch_node_global_id], ego_idx=inv[:batch_size])\n",
    "\n",
    "\n",
    "batch = convert_batch_data(ppr, batch_index, K, dist_subgraph)\n",
    "batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Distributed Batch Loader: Source Node ID -> Local ID\n",
    "2. Convert: local ID + shard ID to global ID\n",
    "3. Construct Subgraph\n",
    "4. Forward Conv\n",
    "5. Compute Loss term of batch nodes\n",
    "6. Backward + Sync"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
