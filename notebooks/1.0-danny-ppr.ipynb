{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 1,  1, 12, 13])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "t = torch.arange(10, 14)\n",
    "index = torch.tensor([True, True, False, False])\n",
    "t[index]= torch.tensor([1, 1])\n",
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPR HOMEWORK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  tensor([0., 0., 0.])  r:  tensor([0.5000, 0.0000, 0.0000])\n",
      "p:  tensor([0.5000, 0.0000, 0.0000])  r:  tensor([0.0000, 0.2500, 0.0000])\n",
      "p:  tensor([0.5000, 0.2500, 0.0000])  r:  tensor([0.0000, 0.0000, 0.1250])\n",
      "p:  tensor([0.5000, 0.2500, 0.1250])  r:  tensor([0.0625, 0.0000, 0.0000])\n",
      "p:  tensor([0.5625, 0.2500, 0.1250])  r:  tensor([0.0000, 0.0312, 0.0000])\n",
      "p:  tensor([0.5625, 0.2812, 0.1250])  r:  tensor([0.0000, 0.0000, 0.0156])\n",
      "p:  tensor([0.5625, 0.2812, 0.1406])  r:  tensor([0.0078, 0.0000, 0.0000])\n",
      "p:  tensor([0.5703, 0.2812, 0.1406])  r:  tensor([0.0000, 0.0039, 0.0000])\n",
      "p:  tensor([0.5703, 0.2852, 0.1406])  r:  tensor([0.0000, 0.0000, 0.0020])\n",
      "p:  tensor([0.5703, 0.2852, 0.1426])  r:  tensor([0.0010, 0.0000, 0.0000])\n",
      "p:  tensor([0.5713, 0.2852, 0.1426])  r:  tensor([0.0000, 0.0005, 0.0000])\n",
      "p:  tensor([0.5713, 0.2856, 0.1426])  r:  tensor([0.0000, 0.0000, 0.0002])\n",
      "p:  tensor([0.5713, 0.2856, 0.1428])  r:  tensor([0.0001, 0.0000, 0.0000])\n",
      "p:  tensor([0.5714, 0.2856, 0.1428])  r:  tensor([0.0000e+00, 6.1035e-05, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1428])  r:  tensor([0.0000e+00, 0.0000e+00, 3.0518e-05])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([1.5259e-05, 0.0000e+00, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([0.0000e+00, 7.6294e-06, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([0.0000e+00, 0.0000e+00, 3.8147e-06])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.5714, 0.2857, 0.1429])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr = torch.tensor([0, 1, 2, 3])\n",
    "indices = torch.tensor([1, 2, 0])\n",
    "degree = torch.tensor([1, 1, 1])\n",
    "g = (indptr, indices, degree)\n",
    "\n",
    "\n",
    "def approx_ppr(g_, a_, t_, e_):\n",
    "    indptr_, indices_, degree_ = g_\n",
    "    num_nodes = degree_.size(-1)\n",
    "\n",
    "    # initialize\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[t_] = a_\n",
    "\n",
    "    threshold = a_ * e_ * degree_\n",
    "    while True:\n",
    "        print('p: ', p, ' r: ', r)\n",
    "        mask = r > threshold\n",
    "        if mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # update\n",
    "        p[mask] += r[mask]\n",
    "        m = (1 - a_) * r[mask] / degree_[mask]\n",
    "        r[mask] = 0\n",
    "\n",
    "        # can be optimized by using scatter()\n",
    "        v_idx = mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            u_idx = indices_[indptr_[v]: indptr_[v+1]]\n",
    "            r[u_idx] += m[i]\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "ppr_score = approx_ppr(g, 0.5, 0, 1e-5)\n",
    "ppr_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPR Experiments (power-iter vs local-push)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def power_iter_ppr(P_w, target_id_, alpha_, epsilon_, max_iter, unweighted_degree_):\n",
    "    num_nodes = P_w.size(0)\n",
    "    s = torch.zeros(num_nodes)\n",
    "    s[target_id_] = 1\n",
    "    s = s.view(-1, 1)\n",
    "\n",
    "    x = s.clone()\n",
    "    num_push = 0\n",
    "    for i in range(max_iter):\n",
    "        x_last = x\n",
    "        x = alpha_ * s + (1 - alpha_) * (P_w @ x)\n",
    "        # total num of operations\n",
    "        x_last_nnz_index = x_last.view(-1).nonzero(as_tuple=False).view(-1)\n",
    "        num_push += unweighted_degree_[x_last_nnz_index].sum()\n",
    "        # check convergence, l1 norm\n",
    "        if (abs(x - x_last)).sum() < num_nodes * epsilon_:\n",
    "            print(f'power-iter      Iterations: {i}, Total Push Operations: {num_push.item()},'\n",
    "                  f' NNZ: {(x.view(-1) > 0).sum()}')\n",
    "            return x.view(-1), num_push.item()\n",
    "\n",
    "    print(f'Failed to converge with tolerance({epsilon_}) and iter({max_iter})')\n",
    "    return x.view(-1), num_push.item()\n",
    "\n",
    "\n",
    "def standard_local_push_ppr(g_, target_id_, alpha_, epsilon_, beta_=0., gamma_=1., max_degree_=-1, drop_coe_=0):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations = num_push = 0\n",
    "    num_affected_nodes = num_affected_edges = 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    drop_threshold = drop_coe_ * threshold\n",
    "    bias = beta_ * threshold\n",
    "\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        # if iterations == 15:\n",
    "        #     break\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # drop nodes below specific threshold\n",
    "        # print(((r < drop_threshold) & (r > 0)).sum().item())\n",
    "        r[(r < drop_threshold) & (r > 0)] = 0\n",
    "\n",
    "        v_idx = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "            num_degree = end - start\n",
    "            if max_degree_ == -1 or num_degree <= max_degree_:\n",
    "                ptr = torch.arange(start, end)\n",
    "            else:\n",
    "                ptr = torch.randperm(num_degree)[:max_degree_] + start\n",
    "                num_affected_nodes += 1\n",
    "                num_affected_edges += num_degree - max_degree_\n",
    "\n",
    "            u_idx = g_['indices'][ptr]\n",
    "            u_weights = g_['edge_weights'][ptr]\n",
    "\n",
    "            while r[v] > threshold[v]:\n",
    "                # update source node\n",
    "                if beta_ == 0:\n",
    "                    p[v] += alpha_ * r[v]\n",
    "                    m_v = (1 - alpha_) * gamma_ * r[v]\n",
    "                    r[v] = (1 - alpha_) * (1 - gamma_) * r[v]\n",
    "                else:\n",
    "                    p[v] += alpha_ * (r[v] - bias[v])\n",
    "                    m_v = (1 - alpha_) * (r[v] - bias[v])\n",
    "                    r[v] = bias[v]\n",
    "\n",
    "                # batch update neighbors\n",
    "                r[u_idx] += m_v * (u_weights / u_weights.sum())\n",
    "\n",
    "                num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return p, iterations, num_push.item(), num_affected_nodes, num_affected_edges\n",
    "\n",
    "\n",
    "def uniform_local_push_ppr(g_, target_id_, alpha_, epsilon_, gamma_=1.):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations, num_push = 0, 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        v_idx = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            # update source node\n",
    "            p[v] += alpha_ * r[v]\n",
    "            temp = (1 - alpha_) * r[v]\n",
    "            r[v] = (1 - gamma_) * temp\n",
    "            m_v = gamma_ * temp / g_['weighted_degree'][v]\n",
    "\n",
    "            # batch update neighbors\n",
    "            start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "            u_idx = g_['indices'][start: end]\n",
    "            u_weights = g_['edge_weights'][start: end]\n",
    "            r[u_idx] += m_v * u_weights\n",
    "\n",
    "            num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return p, iterations, num_push.item(), 0, 0\n",
    "\n",
    "\n",
    "def batch_local_push_ppr(g_, target_id_, alpha_, epsilon_, gamma_=1., max_degree_=-1, drop_coe_=0):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations = num_push = 0\n",
    "    num_affected_nodes = num_affected_edges = 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    drop_threshold = drop_coe_ * threshold\n",
    "\n",
    "    num_p = 0\n",
    "\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # drop nodes below specific threshold\n",
    "        r[(r < drop_threshold) & (r > 0)] = 0\n",
    "\n",
    "        v_idx_ = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        # while True:\n",
    "        #     v_mask_ = r[v_idx] > threshold[v_idx]\n",
    "        #     if v_mask_.sum() == 0:\n",
    "        #         break\n",
    "        #     v_idx_ = v_idx[v_mask_]\n",
    "\n",
    "        print(v_idx_.numel())\n",
    "        num_p += v_idx_.numel()\n",
    "\n",
    "        # batch update source nodes\n",
    "        p[v_idx_] += alpha_ * r[v_idx_]\n",
    "        m = (1 - alpha_) * r[v_idx_]\n",
    "        r[v_idx_] = (1 - gamma_) * m\n",
    "        m = gamma_ * m\n",
    "\n",
    "        for i, v in enumerate(v_idx_):\n",
    "            start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "            num_degree = end - start\n",
    "            if max_degree_ == -1 or num_degree <= max_degree_:\n",
    "                ptr = torch.arange(start, end)\n",
    "            else:\n",
    "                ptr = torch.randperm(num_degree)[:max_degree_] + start\n",
    "                num_affected_nodes += 1\n",
    "                num_affected_edges += num_degree - max_degree_\n",
    "            # batch update neighbors\n",
    "            u_idx = g_['indices'][ptr]\n",
    "            u_weights = g_['edge_weights'][ptr]\n",
    "            r[u_idx] += m[i] * u_weights / u_weights.sum()\n",
    "\n",
    "            num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    print('Total Num P', num_p)\n",
    "    return p, iterations, num_push.item(), num_affected_nodes, num_affected_edges"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "outputs": [
    {
     "data": {
      "text/plain": "({'indptr': tensor([        0,       174,       263,  ..., 123718233, 123718242,\n          123718280]),\n  'indices': tensor([    384,    2412,    7554,  ..., 1787657, 1864057, 2430488]),\n  'edge_weights': tensor([0.9730, 0.2058, 0.4334,  ..., 0.3425, 0.5531, 0.6257]),\n  'weighted_degree': tensor([84.7882, 42.4940, 20.5972,  ..., 22.7808,  6.3245, 17.3090])},\n SparseTensor(row=tensor([      0,       0,       0,  ..., 2449028, 2449028, 2449028]),\n              col=tensor([    384,    2412,    7554,  ..., 1787657, 1864057, 2430488]),\n              val=tensor([0.0199, 0.0041, 0.0047,  ..., 0.0050, 0.0024, 0.0793]),\n              size=(2449029, 2449029), nnz=123718280, density=0.00%))"
     },
     "execution_count": 1227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "\"\"\"Graph Loading\"\"\"\n",
    "dataset = PygNodePropPredDataset(name='ogbn-products', root='/data/gangda/ogb', transform=T.ToSparseTensor())\n",
    "# dataset = Planetoid(root='/data/gangda/pyg', name='Cora', pre_transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "unweighted_degree = data.adj_t.sum(dim=0).to(torch.int)\n",
    "coo_adj_edge_weight = torch.rand(data.num_edges)\n",
    "# coo_adj_edge_weight = torch.ones(data.num_edges)\n",
    "data.adj_t.set_value_(coo_adj_edge_weight, layout='csc')\n",
    "\n",
    "# local-push\n",
    "indptr, indices, value = data.adj_t.csc()\n",
    "degree = data.adj_t.sum(dim=0).to(torch.float)\n",
    "g = {\n",
    "    'indptr': indptr,\n",
    "    'indices': indices,\n",
    "    'edge_weights': value,\n",
    "    'weighted_degree': degree,\n",
    "}\n",
    "\n",
    "# power-iteration\n",
    "norm_adj_t = data.adj_t * degree.pow(-1).view(1, -1)\n",
    "\n",
    "g, norm_adj_t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1231,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(174, dtype=torch.int32)"
     },
     "execution_count": 1231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unweighted_degree[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nodes affected ratio of different max degree\n",
    "- 1000 0.1%\n",
    "- 350 1%\n",
    "- 200 3%\n",
    "- 150 6%\n",
    "- 100 12%\n",
    "- 80 18%\n",
    "- 60 24%\n",
    "- 50 30%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.2585)"
     },
     "execution_count": 1142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unweighted_degree > 60).sum() / data.num_nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "outputs": [
    {
     "data": {
      "text/plain": "{'indptr': tensor([    0,     3,     6,  ..., 10530, 10534, 10538]),\n 'indices': tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n 'edge_weights': tensor([0.2110, 0.0817, 0.7195,  ..., 0.5115, 0.7540, 0.7701]),\n 'weighted_degree': tensor([1.0122, 0.9240, 2.2092,  ..., 0.2975, 2.3681, 2.1038])}"
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Deprecated Sampling\"\"\"\n",
    "# sampled local-push\n",
    "adj = data.adj_t.t()\n",
    "adj = adj.sample_adj(torch.arange(data.num_nodes), 150, replace=False)[0]\n",
    "_indptr, _indices, _value = adj.csr()\n",
    "_degree = adj.sum(dim=1).to(torch.float)\n",
    "g_sampled = {\n",
    "    'indptr': _indptr,\n",
    "    'indices': _indices,\n",
    "    'edge_weights': _value,\n",
    "    'weighted_degree': _degree,\n",
    "}\n",
    "g_sampled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1232,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Iter 1 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 668906608, NNZ: 2333488\n",
      "1\n",
      "84\n",
      "2342\n",
      "1321\n",
      "898\n",
      "393\n",
      "166\n",
      "68\n",
      "27\n",
      "6\n",
      "Total Num P 5306\n",
      "batch           Iterations: 10, Total Push Operations: 493200, NNZ: 3584, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "84\n",
      "2342\n",
      "1037\n",
      "473\n",
      "53\n",
      "6\n",
      "Total Num P 3996\n",
      "drop-batch      Iterations: 7, Total Push Operations: 395641, NNZ: 2924, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 2 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 728417919, NNZ: 2359825\n",
      "1\n",
      "102\n",
      "2519\n",
      "924\n",
      "476\n",
      "124\n",
      "33\n",
      "7\n",
      "1\n",
      "Total Num P 4187\n",
      "batch           Iterations: 9, Total Push Operations: 348308, NNZ: 3832, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "102\n",
      "2519\n",
      "655\n",
      "101\n",
      "10\n",
      "Total Num P 3388\n",
      "drop-batch      Iterations: 6, Total Push Operations: 277080, NNZ: 3153, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 3 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 713405595, NNZ: 2359823\n",
      "1\n",
      "11\n",
      "555\n",
      "828\n",
      "619\n",
      "414\n",
      "231\n",
      "80\n",
      "44\n",
      "9\n",
      "7\n",
      "1\n",
      "Total Num P 2800\n",
      "batch           Iterations: 12, Total Push Operations: 137532, NNZ: 1359, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "11\n",
      "555\n",
      "802\n",
      "527\n",
      "338\n",
      "163\n",
      "41\n",
      "9\n",
      "Total Num P 2447\n",
      "drop-batch      Iterations: 9, Total Push Operations: 122359, NNZ: 1206, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 4 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 616119887, NNZ: 2333485\n",
      "1\n",
      "19\n",
      "317\n",
      "960\n",
      "796\n",
      "468\n",
      "207\n",
      "91\n",
      "35\n",
      "22\n",
      "8\n",
      "Total Num P 2924\n",
      "batch           Iterations: 11, Total Push Operations: 122574, NNZ: 1643, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "19\n",
      "317\n",
      "949\n",
      "678\n",
      "322\n",
      "120\n",
      "48\n",
      "16\n",
      "7\n",
      "4\n",
      "1\n",
      "Total Num P 2482\n",
      "drop-batch      Iterations: 12, Total Push Operations: 103011, NNZ: 1381, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 5 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 663328401, NNZ: 2333486\n",
      "1\n",
      "97\n",
      "2111\n",
      "1617\n",
      "864\n",
      "345\n",
      "109\n",
      "28\n",
      "6\n",
      "3\n",
      "1\n",
      "1\n",
      "Total Num P 5183\n",
      "batch           Iterations: 12, Total Push Operations: 351363, NNZ: 3517, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "97\n",
      "2111\n",
      "1357\n",
      "493\n",
      "89\n",
      "23\n",
      "6\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "Total Num P 4183\n",
      "drop-batch      Iterations: 12, Total Push Operations: 284126, NNZ: 2860, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 6 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 566612855, NNZ: 2329823\n",
      "1\n",
      "3\n",
      "15\n",
      "331\n",
      "274\n",
      "124\n",
      "60\n",
      "28\n",
      "10\n",
      "11\n",
      "5\n",
      "3\n",
      "Total Num P 865\n",
      "batch           Iterations: 12, Total Push Operations: 69592, NNZ: 649, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "3\n",
      "15\n",
      "331\n",
      "197\n",
      "70\n",
      "47\n",
      "16\n",
      "9\n",
      "7\n",
      "5\n",
      "3\n",
      "Total Num P 704\n",
      "drop-batch      Iterations: 12, Total Push Operations: 57137, NNZ: 504, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 7 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 635690023, NNZ: 2333479\n",
      "1\n",
      "18\n",
      "368\n",
      "423\n",
      "330\n",
      "235\n",
      "150\n",
      "81\n",
      "49\n",
      "27\n",
      "22\n",
      "17\n",
      "3\n",
      "Total Num P 1724\n",
      "batch           Iterations: 13, Total Push Operations: 95230, NNZ: 943, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "18\n",
      "368\n",
      "414\n",
      "252\n",
      "114\n",
      "51\n",
      "27\n",
      "21\n",
      "19\n",
      "19\n",
      "16\n",
      "2\n",
      "Total Num P 1322\n",
      "drop-batch      Iterations: 13, Total Push Operations: 74237, NNZ: 735, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 8 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 632044723, NNZ: 2338897\n",
      "1\n",
      "11\n",
      "1081\n",
      "902\n",
      "970\n",
      "435\n",
      "266\n",
      "126\n",
      "40\n",
      "14\n",
      "Total Num P 3846\n",
      "batch           Iterations: 10, Total Push Operations: 302759, NNZ: 1936, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "11\n",
      "1081\n",
      "823\n",
      "709\n",
      "245\n",
      "130\n",
      "27\n",
      "1\n",
      "Total Num P 3028\n",
      "drop-batch      Iterations: 9, Total Push Operations: 242346, NNZ: 1501, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 9 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 526723133, NNZ: 2329840\n",
      "1\n",
      "5\n",
      "139\n",
      "1582\n",
      "1179\n",
      "710\n",
      "320\n",
      "136\n",
      "36\n",
      "7\n",
      "2\n",
      "Total Num P 4117\n",
      "batch           Iterations: 11, Total Push Operations: 167165, NNZ: 2681, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "5\n",
      "139\n",
      "1582\n",
      "967\n",
      "430\n",
      "109\n",
      "31\n",
      "8\n",
      "3\n",
      "1\n",
      "Total Num P 3276\n",
      "drop-batch      Iterations: 11, Total Push Operations: 136092, NNZ: 2199, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 10 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 703692992, NNZ: 2338907\n",
      "1\n",
      "41\n",
      "1200\n",
      "892\n",
      "654\n",
      "254\n",
      "88\n",
      "30\n",
      "25\n",
      "15\n",
      "1\n",
      "1\n",
      "2\n",
      "Total Num P 3204\n",
      "batch           Iterations: 13, Total Push Operations: 238608, NNZ: 1735, Clipped Nodes(Edges): 0(0)\n",
      "1\n",
      "41\n",
      "1200\n",
      "814\n",
      "516\n",
      "123\n",
      "24\n",
      "2\n",
      "Total Num P 2721\n",
      "drop-batch      Iterations: 8, Total Push Operations: 198048, NNZ: 1485, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "\n",
      "########## Results ##########\n",
      "Parameters: lazy_alpha=0.3, alpha=0.462, epsilon=1.0e-06, max_degree=1000, drop_coe=0.8\n",
      "\n",
      "Avg Push Operations:\n",
      "\tpower-iter: 645494214\n",
      "\tbatch: 232633\n",
      "\tdrop-batch: 189008\n",
      "\n",
      "Avg Clipped Nodes(Edges):\n",
      "\tbatch: 0(0)\n",
      "\tdrop-batch: 0(0)\n",
      "\n",
      "Precision Top-100:\n",
      "\tbatch: 0.946\n",
      "\tdrop-batch: 0.937\n",
      "\n",
      "mean power-iter ppr:  4.083e-07\n",
      "Mean Absolute Error:\n",
      "\tbatch: 3.980e-08\n",
      "\tdrop-batch: 4.451e-08\n",
      "\n",
      "Avg Run Time:\n",
      "\tpower-iter: 4.025s\n",
      "\tbatch: 3.278s\n",
      "\tdrop-batch: 3.310s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\"\"\"Testing\"\"\"\n",
    "lazy_alpha = 0.3\n",
    "alpha = (2 * lazy_alpha) / (1 + lazy_alpha)\n",
    "epsilon = 1e-6\n",
    "\n",
    "max_degree = 1000\n",
    "drop_coe = 0.8\n",
    "\n",
    "top_k = 100\n",
    "num_source = 10\n",
    "\n",
    "# Modify your test:\n",
    "test_list = ['batch', 'drop-batch']\n",
    "\n",
    "def get_approx_ppr(key_, target_id_):\n",
    "    ppr_func_dict = {\n",
    "        'standard': standard_local_push_ppr,  # PPRGo, r_v = 0\n",
    "        'uniform': uniform_local_push_ppr,  # same as 'standard'\n",
    "        'batch': batch_local_push_ppr,  # update all source nodes simultaneously\n",
    "        'bias': standard_local_push_ppr,  # MAPPR, 0 < r_v < threshold\n",
    "        'lazy': standard_local_push_ppr,  # original local-push\n",
    "        'lazy-uniform': uniform_local_push_ppr,\n",
    "        'lazy-batch': batch_local_push_ppr,\n",
    "        'clipped': standard_local_push_ppr,  # 'standard' ppr on clipped graph\n",
    "        'clipped-lazy': standard_local_push_ppr,\n",
    "        'clipped-batch': batch_local_push_ppr,\n",
    "        'drop': standard_local_push_ppr,\n",
    "        'drop-batch': batch_local_push_ppr,\n",
    "    }\n",
    "    kwargs = {\n",
    "        'alpha_': lazy_alpha if 'lazy' in key_ else alpha,\n",
    "        'gamma_': 0.5 if 'lazy' in key_ else 1.,\n",
    "        'epsilon_': epsilon,\n",
    "    }\n",
    "    if 'bias' in key_:\n",
    "        kwargs['beta_'] = 0.5\n",
    "    if 'clipped' in key_:\n",
    "        kwargs['max_degree_'] = max_degree\n",
    "    if 'drop' in key_:\n",
    "        kwargs['drop_coe_'] = drop_coe\n",
    "    return ppr_func_dict[key_](g, target_id_, **kwargs)\n",
    "\n",
    "total_base_p = 0.\n",
    "total_concur, total_err, total_push = defaultdict(int), defaultdict(float), defaultdict(int)\n",
    "total_clipped_nodes, total_clipped_edges = defaultdict(int), defaultdict(int)\n",
    "total_time = defaultdict(float)\n",
    "\n",
    "source_nodes = torch.randperm(data.num_nodes)[:num_source]\n",
    "for epoch, target_id in enumerate(source_nodes):\n",
    "    print(f'\\n########## Iter {epoch+1} ##########')\n",
    "\n",
    "    tik = time.time()\n",
    "    base_p, base_num_push = power_iter_ppr(norm_adj_t, target_id, alpha, 1e-10, 100, unweighted_degree)\n",
    "    total_time['power-iter'] += time.time() - tik\n",
    "\n",
    "    total_base_p += base_p\n",
    "    total_push['power-iter'] += base_num_push\n",
    "    _, base_top_k = torch.sort(base_p, descending=True)\n",
    "\n",
    "    for key in test_list:\n",
    "        tik = time.time()\n",
    "        approx_p, approx_num_iter, approx_num_push, num_clipped_nodes, num_clipped_edges = get_approx_ppr(key, target_id)\n",
    "        total_time[key] += time.time() - tik\n",
    "\n",
    "        print(f'{key:15s} Iterations: {approx_num_iter}, Total Push Operations: {approx_num_push}, NNZ: {(approx_p > 0).sum()}, Clipped Nodes(Edges): {num_clipped_nodes}({num_clipped_edges})')\n",
    "\n",
    "        total_push[key] += approx_num_push\n",
    "        total_err[key] += (abs(approx_p - base_p)).sum().item()\n",
    "        _, approx_top_k = torch.sort(approx_p, descending=True)\n",
    "        total_concur[key] += np.intersect1d(base_top_k[:top_k], approx_top_k[:top_k]).shape[0]\n",
    "\n",
    "        total_clipped_nodes[key] += num_clipped_nodes\n",
    "        total_clipped_edges[key] += num_clipped_edges\n",
    "\n",
    "# print overall results\n",
    "print(f'\\n\\n########## Results ##########')\n",
    "print(f'Parameters: lazy_alpha={lazy_alpha}, alpha={alpha:.3f}, epsilon={epsilon:.1e}, max_degree={max_degree}, drop_coe={drop_coe}')\n",
    "\n",
    "print(f'\\nAvg Push Operations:')\n",
    "for k, val in total_push.items():\n",
    "    print(f'\\t{k}: {val/num_source:.0f}')\n",
    "\n",
    "print(f'\\nAvg Clipped Nodes(Edges):')\n",
    "for k, val in total_clipped_nodes.items():\n",
    "    print(f'\\t{k}: {val/num_source:.0f}({total_clipped_edges[k]/num_source:.0f})')\n",
    "\n",
    "print(f'\\nPrecision Top-{top_k}:')\n",
    "for k, val in total_concur.items():\n",
    "    print(f'\\t{k}: {val/(top_k * num_source):.3f}')\n",
    "\n",
    "print(f'\\nmean power-iter ppr: {total_base_p.mean().item()/num_source: .3e}'\n",
    "      f'\\nMean Absolute Error:')\n",
    "for k, val in total_err.items():\n",
    "    print(f'\\t{k}: {val/(data.num_nodes*num_source):.3e}')\n",
    "\n",
    "print(f'\\nAvg Run Time:')\n",
    "for k, val in total_time.items():\n",
    "    print(f'\\t{k}: {val/num_source:.3f}s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPRGO (close to C implementation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _calc_ppr_node(target_id_, indptr_, indices_, degree_, weights_, alpha_, epsilon_):\n",
    "    alpha_eps = alpha_ * epsilon_\n",
    "    f32_0 = 0.\n",
    "    p = {target_id_: f32_0}\n",
    "    r = {target_id_: alpha_}\n",
    "    q = [target_id_]\n",
    "    while len(q) > 0:\n",
    "        unode = q.pop()\n",
    "\n",
    "        res = r[unode] if unode in r else f32_0\n",
    "        if unode in p:\n",
    "            p[unode] += res\n",
    "        else:\n",
    "            p[unode] = res\n",
    "        r[unode] = f32_0\n",
    "        for vnode in indices_[indptr_[unode]:indptr_[unode + 1]]:\n",
    "            _val = (1 - alpha_) * res * weights_[unode] / degree_[unode]\n",
    "            if vnode in r:\n",
    "                r[vnode] += _val\n",
    "            else:\n",
    "                r[vnode] = _val\n",
    "\n",
    "            res_vnode = r[vnode] if vnode in r else f32_0\n",
    "            if res_vnode >= alpha_eps * degree_[vnode]:\n",
    "                if vnode not in q:\n",
    "                    q.append(vnode)\n",
    "\n",
    "    return list(p.keys()), list(p.values())\n",
    "\n",
    "# PPRGO Implementation, needs numba compiler acceleration\n",
    "# Root nodes level parallelization\n",
    "_calc_ppr_node(0, indptr.tolist(), indices.tolist(), degree.tolist(), value.tolist(), 0.15, 1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}