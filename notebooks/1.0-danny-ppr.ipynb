{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 1,  1, 12, 13])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "t = torch.arange(10, 14)\n",
    "index = torch.tensor([True, True, False, False])\n",
    "t[index]= torch.tensor([1, 1])\n",
    "t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPR HOMEWORK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  tensor([0., 0., 0.])  r:  tensor([0.5000, 0.0000, 0.0000])\n",
      "p:  tensor([0.5000, 0.0000, 0.0000])  r:  tensor([0.0000, 0.2500, 0.0000])\n",
      "p:  tensor([0.5000, 0.2500, 0.0000])  r:  tensor([0.0000, 0.0000, 0.1250])\n",
      "p:  tensor([0.5000, 0.2500, 0.1250])  r:  tensor([0.0625, 0.0000, 0.0000])\n",
      "p:  tensor([0.5625, 0.2500, 0.1250])  r:  tensor([0.0000, 0.0312, 0.0000])\n",
      "p:  tensor([0.5625, 0.2812, 0.1250])  r:  tensor([0.0000, 0.0000, 0.0156])\n",
      "p:  tensor([0.5625, 0.2812, 0.1406])  r:  tensor([0.0078, 0.0000, 0.0000])\n",
      "p:  tensor([0.5703, 0.2812, 0.1406])  r:  tensor([0.0000, 0.0039, 0.0000])\n",
      "p:  tensor([0.5703, 0.2852, 0.1406])  r:  tensor([0.0000, 0.0000, 0.0020])\n",
      "p:  tensor([0.5703, 0.2852, 0.1426])  r:  tensor([0.0010, 0.0000, 0.0000])\n",
      "p:  tensor([0.5713, 0.2852, 0.1426])  r:  tensor([0.0000, 0.0005, 0.0000])\n",
      "p:  tensor([0.5713, 0.2856, 0.1426])  r:  tensor([0.0000, 0.0000, 0.0002])\n",
      "p:  tensor([0.5713, 0.2856, 0.1428])  r:  tensor([0.0001, 0.0000, 0.0000])\n",
      "p:  tensor([0.5714, 0.2856, 0.1428])  r:  tensor([0.0000e+00, 6.1035e-05, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1428])  r:  tensor([0.0000e+00, 0.0000e+00, 3.0518e-05])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([1.5259e-05, 0.0000e+00, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([0.0000e+00, 7.6294e-06, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([0.0000e+00, 0.0000e+00, 3.8147e-06])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.5714, 0.2857, 0.1429])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr = torch.tensor([0, 1, 2, 3])\n",
    "indices = torch.tensor([1, 2, 0])\n",
    "degree = torch.tensor([1, 1, 1])\n",
    "g = (indptr, indices, degree)\n",
    "\n",
    "\n",
    "def approx_ppr(g_, a_, t_, e_):\n",
    "    indptr_, indices_, degree_ = g_\n",
    "    num_nodes = degree_.size(-1)\n",
    "\n",
    "    # initialize\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[t_] = a_\n",
    "\n",
    "    threshold = a_ * e_ * degree_\n",
    "    while True:\n",
    "        print('p: ', p, ' r: ', r)\n",
    "        mask = r > threshold\n",
    "        if mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # update\n",
    "        p[mask] += r[mask]\n",
    "        m = (1 - a_) * r[mask] / degree_[mask]\n",
    "        r[mask] = 0\n",
    "\n",
    "        # can be optimized by using scatter()\n",
    "        v_idx = mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            u_idx = indices_[indptr_[v]: indptr_[v+1]]\n",
    "            r[u_idx] += m[i]\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "ppr_score = approx_ppr(g, 0.5, 0, 1e-5)\n",
    "ppr_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPR EXP (power-iter vs local-push)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "outputs": [],
   "source": [
    "def power_iter_ppr(P_w, target_id_, alpha_, epsilon_, max_iter, unweighted_degree_):\n",
    "    num_nodes = P_w.size(0)\n",
    "    s = torch.zeros(num_nodes)\n",
    "    s[target_id_] = 1\n",
    "    s = s.view(-1, 1)\n",
    "\n",
    "    x = s.clone()\n",
    "    num_push = 0\n",
    "    for i in range(max_iter):\n",
    "        x_last = x\n",
    "        x = alpha_ * s + (1 - alpha_) * (P_w @ x)\n",
    "        # total num of operations\n",
    "        x_last_nnz_index = x_last.view(-1).nonzero(as_tuple=False).view(-1)\n",
    "        num_push += unweighted_degree_[x_last_nnz_index].sum()\n",
    "        # check convergence, l1 norm\n",
    "        if sum(abs(x - x_last)) < num_nodes * epsilon_:\n",
    "            print(f'power-iter      Iterations: {i}, Total Push Operations: {num_push.item()},'\n",
    "                  f' NNZ: {sum(x.view(-1) > 0)}')\n",
    "            return x.view(-1), num_push.item()\n",
    "\n",
    "    print(f'Failed to converge with tolerance({epsilon_}) and iter({max_iter})')\n",
    "    return x.view(-1), num_push.item()\n",
    "\n",
    "\n",
    "def standard_local_push_ppr(g_, target_id_, alpha_, epsilon_, beta_=0., gamma_=1.):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations, num_push = 0, 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    bias = beta_ * threshold\n",
    "\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        v_idx = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "            u_idx = g_['indices'][start: end]\n",
    "            u_weights = g_['edge_weights'][start: end]\n",
    "\n",
    "            while r[v] > threshold[v]:\n",
    "                # update source node\n",
    "                if beta_ == 0:\n",
    "                    p[v] += alpha_ * r[v]\n",
    "                    m_v = (1 - alpha_) * gamma_ * r[v]\n",
    "                    r[v] = (1 - alpha_) * (1 - gamma_) * r[v]\n",
    "                else:\n",
    "                    p[v] += alpha_ * (r[v] - bias[v])\n",
    "                    m_v = (1 - alpha_) * (r[v] - bias[v])\n",
    "                    r[v] = bias[v]\n",
    "\n",
    "                # batch update neighbors\n",
    "                r[u_idx] += m_v * (u_weights / g_['weighted_degree'][v])\n",
    "\n",
    "                num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return p, iterations, num_push.item()\n",
    "\n",
    "\n",
    "def uniform_local_push_ppr(g_, target_id_, alpha_, epsilon_, beta_=0., gamma_=1.):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations, num_push = 0, 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        v_idx = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            # update source node\n",
    "            p[v] += alpha_ * r[v]\n",
    "            temp = (1 - alpha_) * r[v]\n",
    "            r[v] = (1 - gamma_) * temp\n",
    "            m_v = gamma_ * temp / g_['weighted_degree'][v]\n",
    "\n",
    "            # batch update neighbors\n",
    "            start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "            u_idx = g_['indices'][start: end]\n",
    "            u_weights = g_['edge_weights'][start: end]\n",
    "            r[u_idx] += m_v * u_weights\n",
    "\n",
    "            num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return p, iterations, num_push.item()\n",
    "\n",
    "\n",
    "def batch_local_push_ppr(g_, target_id_, alpha_, epsilon_, beta_=0., gamma_=1.):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations, num_push = 0, 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        v_idx = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        while True:\n",
    "            v_mask_ = r[v_idx] > threshold[v_idx]\n",
    "            if v_mask_.sum() == 0:\n",
    "                break\n",
    "            v_idx_ = v_idx[v_mask_]\n",
    "\n",
    "            # batch update source nodes\n",
    "            p[v_idx_] += alpha_ * r[v_idx_]\n",
    "            m = (1 - alpha_) * r[v_idx_]\n",
    "            r[v_idx_] = (1 - gamma_) * m\n",
    "            m = gamma_ * m / g_['weighted_degree'][v_idx_]\n",
    "\n",
    "            for i, v in enumerate(v_idx_):\n",
    "                # batch update neighbors\n",
    "                start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "                u_idx = g_['indices'][start: end]\n",
    "                u_weights = g_['edge_weights'][start: end]\n",
    "                r[u_idx] += m[i] * u_weights\n",
    "\n",
    "                num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return p, iterations, num_push.item()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "outputs": [
    {
     "data": {
      "text/plain": "({'indptr': tensor([    0,     3,     6,  ..., 10548, 10552, 10556]),\n  'indices': tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n  'edge_weights': tensor([0.2110, 0.0817, 0.7195,  ..., 0.5115, 0.7540, 0.7701]),\n  'weighted_degree': tensor([1.0122, 0.9240, 2.2092,  ..., 0.2975, 2.3681, 2.1038])},\n SparseTensor(row=tensor([   0,    0,    0,  ..., 2707, 2707, 2707]),\n              col=tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n              val=tensor([0.2295, 0.2648, 0.3536,  ..., 0.0463, 0.4751, 0.4024]),\n              size=(2708, 2708), nnz=10556, density=0.14%))"
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Planetoid(root='/data/gangda/pyg', name='Cora', pre_transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "unweighted_degree = data.adj_t.sum(dim=0).to(torch.int)\n",
    "coo_adj_edge_weight = torch.rand(data.num_edges)\n",
    "# coo_adj_edge_weight = torch.ones(data.num_edges)\n",
    "data.adj_t.set_value_(coo_adj_edge_weight, layout='csc')\n",
    "\n",
    "# local-push\n",
    "indptr, indices, value = data.adj_t.csc()\n",
    "degree = data.adj_t.sum(dim=0).to(torch.float)\n",
    "g = {\n",
    "    'indptr': indptr,\n",
    "    'indices': indices,\n",
    "    'edge_weights': value,\n",
    "    'weighted_degree': degree,\n",
    "}\n",
    "\n",
    "# power-iteration\n",
    "norm_adj_t = data.adj_t * degree.pow(-1).view(1, -1)\n",
    "\n",
    "g, norm_adj_t"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "outputs": [
    {
     "data": {
      "text/plain": "{'indptr': tensor([    0,     3,     6,  ..., 10530, 10534, 10538]),\n 'indices': tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n 'edge_weights': tensor([0.2110, 0.0817, 0.7195,  ..., 0.5115, 0.7540, 0.7701]),\n 'weighted_degree': tensor([1.0122, 0.9240, 2.2092,  ..., 0.2975, 2.3681, 2.1038])}"
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_DEGREE = 150\n",
    "\n",
    "# sampled local-push\n",
    "adj = data.adj_t.t()\n",
    "adj = adj.sample_adj(torch.arange(data.num_nodes), MAX_DEGREE, replace=False)[0]\n",
    "_indptr, _indices, _value = adj.csr()\n",
    "_degree = adj.sum(dim=1).to(torch.float)\n",
    "g_sampled = {\n",
    "    'indptr': _indptr,\n",
    "    'indices': _indices,\n",
    "    'edge_weights': _value,\n",
    "    'weighted_degree': _degree,\n",
    "}\n",
    "g_sampled"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Iter 1 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 165372, NNZ: 2485\n",
      "standard        Iterations: 17, Total Push Operations: 17655, NNZ: 1116\n",
      "bias            Iterations: 17, Total Push Operations: 20422, NNZ: 1075\n",
      "lazy            Iterations: 17, Total Push Operations: 48152, NNZ: 1083\n",
      "clipped         Iterations: 17, Total Push Operations: 17050, NNZ: 1085\n",
      "\n",
      "########## Iter 2 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 145730, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 11490, NNZ: 888\n",
      "bias            Iterations: 16, Total Push Operations: 13453, NNZ: 861\n",
      "lazy            Iterations: 17, Total Push Operations: 30279, NNZ: 865\n",
      "clipped         Iterations: 15, Total Push Operations: 11490, NNZ: 888\n",
      "\n",
      "########## Iter 3 ##########\n",
      "power-iter      Iterations: 23, Total Push Operations: 174365, NNZ: 2485\n",
      "standard        Iterations: 18, Total Push Operations: 8103, NNZ: 628\n",
      "bias            Iterations: 19, Total Push Operations: 9626, NNZ: 595\n",
      "lazy            Iterations: 20, Total Push Operations: 19588, NNZ: 599\n",
      "clipped         Iterations: 18, Total Push Operations: 7999, NNZ: 622\n",
      "\n",
      "########## Iter 4 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 155226, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 13974, NNZ: 798\n",
      "bias            Iterations: 16, Total Push Operations: 16558, NNZ: 781\n",
      "lazy            Iterations: 17, Total Push Operations: 40961, NNZ: 784\n",
      "clipped         Iterations: 16, Total Push Operations: 13404, NNZ: 763\n",
      "\n",
      "########## Iter 5 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 155610, NNZ: 2485\n",
      "standard        Iterations: 14, Total Push Operations: 15780, NNZ: 1051\n",
      "bias            Iterations: 15, Total Push Operations: 18178, NNZ: 994\n",
      "lazy            Iterations: 16, Total Push Operations: 44711, NNZ: 1002\n",
      "clipped         Iterations: 14, Total Push Operations: 15752, NNZ: 1050\n",
      "\n",
      "########## Iter 6 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 150290, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 10534, NNZ: 731\n",
      "bias            Iterations: 15, Total Push Operations: 12181, NNZ: 714\n",
      "lazy            Iterations: 17, Total Push Operations: 29256, NNZ: 717\n",
      "clipped         Iterations: 15, Total Push Operations: 10509, NNZ: 730\n",
      "\n",
      "########## Iter 7 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 150429, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 11264, NNZ: 856\n",
      "bias            Iterations: 17, Total Push Operations: 13186, NNZ: 838\n",
      "lazy            Iterations: 17, Total Push Operations: 28741, NNZ: 847\n",
      "clipped         Iterations: 16, Total Push Operations: 11264, NNZ: 856\n",
      "\n",
      "########## Iter 8 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 156990, NNZ: 2485\n",
      "standard        Iterations: 13, Total Push Operations: 22290, NNZ: 1551\n",
      "bias            Iterations: 15, Total Push Operations: 26127, NNZ: 1500\n",
      "lazy            Iterations: 17, Total Push Operations: 62233, NNZ: 1509\n",
      "clipped         Iterations: 13, Total Push Operations: 22182, NNZ: 1549\n",
      "\n",
      "########## Iter 9 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 136578, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 6518, NNZ: 520\n",
      "bias            Iterations: 15, Total Push Operations: 7723, NNZ: 503\n",
      "lazy            Iterations: 17, Total Push Operations: 17127, NNZ: 506\n",
      "clipped         Iterations: 15, Total Push Operations: 6518, NNZ: 520\n",
      "\n",
      "########## Iter 10 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 149276, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 16641, NNZ: 1014\n",
      "bias            Iterations: 16, Total Push Operations: 19277, NNZ: 986\n",
      "lazy            Iterations: 19, Total Push Operations: 44221, NNZ: 994\n",
      "clipped         Iterations: 15, Total Push Operations: 16356, NNZ: 1015\n",
      "\n",
      "########## Iter 11 ##########\n",
      "power-iter      Iterations: 25, Total Push Operations: 51, NNZ: 2\n",
      "standard        Iterations: 23, Total Push Operations: 23, NNZ: 2\n",
      "bias            Iterations: 25, Total Push Operations: 25, NNZ: 2\n",
      "lazy            Iterations: 25, Total Push Operations: 195, NNZ: 2\n",
      "clipped         Iterations: 23, Total Push Operations: 23, NNZ: 2\n",
      "\n",
      "########## Iter 12 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 155469, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 10911, NNZ: 624\n",
      "bias            Iterations: 16, Total Push Operations: 12297, NNZ: 610\n",
      "lazy            Iterations: 17, Total Push Operations: 30419, NNZ: 618\n",
      "clipped         Iterations: 15, Total Push Operations: 10363, NNZ: 609\n",
      "\n",
      "########## Iter 13 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 152525, NNZ: 2485\n",
      "standard        Iterations: 17, Total Push Operations: 5059, NNZ: 329\n",
      "bias            Iterations: 17, Total Push Operations: 5925, NNZ: 322\n",
      "lazy            Iterations: 18, Total Push Operations: 15739, NNZ: 324\n",
      "clipped         Iterations: 17, Total Push Operations: 5039, NNZ: 328\n",
      "\n",
      "########## Iter 14 ##########\n",
      "power-iter      Iterations: 18, Total Push Operations: 115479, NNZ: 2485\n",
      "standard        Iterations: 13, Total Push Operations: 3607, NNZ: 225\n",
      "bias            Iterations: 15, Total Push Operations: 4290, NNZ: 221\n",
      "lazy            Iterations: 17, Total Push Operations: 12874, NNZ: 220\n",
      "clipped         Iterations: 13, Total Push Operations: 3607, NNZ: 225\n",
      "\n",
      "########## Iter 15 ##########\n",
      "power-iter      Iterations: 21, Total Push Operations: 1664, NNZ: 26\n",
      "standard        Iterations: 18, Total Push Operations: 680, NNZ: 26\n",
      "bias            Iterations: 19, Total Push Operations: 744, NNZ: 26\n",
      "lazy            Iterations: 21, Total Push Operations: 3163, NNZ: 26\n",
      "clipped         Iterations: 18, Total Push Operations: 680, NNZ: 26\n",
      "\n",
      "########## Iter 16 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 158964, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 12369, NNZ: 911\n",
      "bias            Iterations: 17, Total Push Operations: 14600, NNZ: 879\n",
      "lazy            Iterations: 19, Total Push Operations: 32209, NNZ: 882\n",
      "clipped         Iterations: 15, Total Push Operations: 12349, NNZ: 910\n",
      "\n",
      "########## Iter 17 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 147686, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 14727, NNZ: 1010\n",
      "bias            Iterations: 16, Total Push Operations: 16831, NNZ: 964\n",
      "lazy            Iterations: 17, Total Push Operations: 40348, NNZ: 976\n",
      "clipped         Iterations: 16, Total Push Operations: 14716, NNZ: 1007\n",
      "\n",
      "########## Iter 18 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 138248, NNZ: 2485\n",
      "standard        Iterations: 17, Total Push Operations: 3197, NNZ: 201\n",
      "bias            Iterations: 18, Total Push Operations: 3662, NNZ: 198\n",
      "lazy            Iterations: 20, Total Push Operations: 10298, NNZ: 199\n",
      "clipped         Iterations: 17, Total Push Operations: 3197, NNZ: 201\n",
      "\n",
      "########## Iter 19 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 158344, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 11769, NNZ: 812\n",
      "bias            Iterations: 17, Total Push Operations: 14172, NNZ: 792\n",
      "lazy            Iterations: 17, Total Push Operations: 31981, NNZ: 792\n",
      "clipped         Iterations: 16, Total Push Operations: 11730, NNZ: 810\n",
      "\n",
      "########## Iter 20 ##########\n",
      "power-iter      Iterations: 21, Total Push Operations: 171586, NNZ: 2485\n",
      "standard        Iterations: 17, Total Push Operations: 12004, NNZ: 888\n",
      "bias            Iterations: 17, Total Push Operations: 14219, NNZ: 858\n",
      "lazy            Iterations: 17, Total Push Operations: 28350, NNZ: 864\n",
      "clipped         Iterations: 16, Total Push Operations: 11621, NNZ: 879\n",
      "\n",
      "########## Iter 21 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 148477, NNZ: 2485\n",
      "standard        Iterations: 14, Total Push Operations: 13942, NNZ: 1034\n",
      "bias            Iterations: 15, Total Push Operations: 16233, NNZ: 977\n",
      "lazy            Iterations: 17, Total Push Operations: 37234, NNZ: 993\n",
      "clipped         Iterations: 14, Total Push Operations: 13900, NNZ: 1034\n",
      "\n",
      "########## Iter 22 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 150125, NNZ: 2485\n",
      "standard        Iterations: 18, Total Push Operations: 8300, NNZ: 576\n",
      "bias            Iterations: 17, Total Push Operations: 9722, NNZ: 571\n",
      "lazy            Iterations: 17, Total Push Operations: 21576, NNZ: 571\n",
      "clipped         Iterations: 15, Total Push Operations: 8164, NNZ: 577\n",
      "\n",
      "########## Iter 23 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 155815, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 8922, NNZ: 674\n",
      "bias            Iterations: 17, Total Push Operations: 10455, NNZ: 650\n",
      "lazy            Iterations: 18, Total Push Operations: 23746, NNZ: 649\n",
      "clipped         Iterations: 16, Total Push Operations: 8922, NNZ: 674\n",
      "\n",
      "########## Iter 24 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 146722, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 8974, NNZ: 654\n",
      "bias            Iterations: 16, Total Push Operations: 10555, NNZ: 631\n",
      "lazy            Iterations: 16, Total Push Operations: 23085, NNZ: 642\n",
      "clipped         Iterations: 15, Total Push Operations: 8974, NNZ: 654\n",
      "\n",
      "########## Iter 25 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 157603, NNZ: 2485\n",
      "standard        Iterations: 17, Total Push Operations: 14319, NNZ: 872\n",
      "bias            Iterations: 16, Total Push Operations: 16512, NNZ: 830\n",
      "lazy            Iterations: 18, Total Push Operations: 39478, NNZ: 838\n",
      "clipped         Iterations: 17, Total Push Operations: 14065, NNZ: 871\n",
      "\n",
      "########## Iter 26 ##########\n",
      "power-iter      Iterations: 21, Total Push Operations: 168457, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 14049, NNZ: 1119\n",
      "bias            Iterations: 17, Total Push Operations: 16455, NNZ: 1091\n",
      "lazy            Iterations: 18, Total Push Operations: 35774, NNZ: 1094\n",
      "clipped         Iterations: 16, Total Push Operations: 13859, NNZ: 1105\n",
      "\n",
      "########## Iter 27 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 160247, NNZ: 2485\n",
      "standard        Iterations: 14, Total Push Operations: 19151, NNZ: 1336\n",
      "bias            Iterations: 15, Total Push Operations: 22185, NNZ: 1285\n",
      "lazy            Iterations: 19, Total Push Operations: 51076, NNZ: 1299\n",
      "clipped         Iterations: 14, Total Push Operations: 19103, NNZ: 1332\n",
      "\n",
      "########## Iter 28 ##########\n",
      "power-iter      Iterations: 21, Total Push Operations: 144180, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 3026, NNZ: 175\n",
      "bias            Iterations: 18, Total Push Operations: 3491, NNZ: 171\n",
      "lazy            Iterations: 19, Total Push Operations: 10713, NNZ: 171\n",
      "clipped         Iterations: 16, Total Push Operations: 3026, NNZ: 175\n",
      "\n",
      "########## Iter 29 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 156181, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 12145, NNZ: 807\n",
      "bias            Iterations: 15, Total Push Operations: 14177, NNZ: 790\n",
      "lazy            Iterations: 17, Total Push Operations: 33687, NNZ: 794\n",
      "clipped         Iterations: 16, Total Push Operations: 12350, NNZ: 812\n",
      "\n",
      "########## Iter 30 ##########\n",
      "power-iter      Iterations: 25, Total Push Operations: 51, NNZ: 2\n",
      "standard        Iterations: 24, Total Push Operations: 24, NNZ: 2\n",
      "bias            Iterations: 24, Total Push Operations: 24, NNZ: 2\n",
      "lazy            Iterations: 26, Total Push Operations: 185, NNZ: 2\n",
      "clipped         Iterations: 24, Total Push Operations: 24, NNZ: 2\n",
      "\n",
      "########## Iter 31 ##########\n",
      "power-iter      Iterations: 21, Total Push Operations: 162803, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 9038, NNZ: 632\n",
      "bias            Iterations: 16, Total Push Operations: 10466, NNZ: 615\n",
      "lazy            Iterations: 17, Total Push Operations: 24935, NNZ: 626\n",
      "clipped         Iterations: 15, Total Push Operations: 9038, NNZ: 632\n",
      "\n",
      "########## Iter 32 ##########\n",
      "power-iter      Iterations: 10, Total Push Operations: 123, NNZ: 4\n",
      "standard        Iterations: 19, Total Push Operations: 153, NNZ: 4\n",
      "bias            Iterations: 19, Total Push Operations: 159, NNZ: 4\n",
      "lazy            Iterations: 20, Total Push Operations: 1020, NNZ: 4\n",
      "clipped         Iterations: 19, Total Push Operations: 153, NNZ: 4\n",
      "\n",
      "########## Iter 33 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 165500, NNZ: 2485\n",
      "standard        Iterations: 14, Total Push Operations: 18083, NNZ: 1263\n",
      "bias            Iterations: 16, Total Push Operations: 21047, NNZ: 1217\n",
      "lazy            Iterations: 20, Total Push Operations: 48900, NNZ: 1227\n",
      "clipped         Iterations: 14, Total Push Operations: 18037, NNZ: 1258\n",
      "\n",
      "########## Iter 34 ##########\n",
      "power-iter      Iterations: 21, Total Push Operations: 170958, NNZ: 2485\n",
      "standard        Iterations: 18, Total Push Operations: 12419, NNZ: 884\n",
      "bias            Iterations: 19, Total Push Operations: 14253, NNZ: 848\n",
      "lazy            Iterations: 20, Total Push Operations: 33602, NNZ: 857\n",
      "clipped         Iterations: 18, Total Push Operations: 12419, NNZ: 884\n",
      "\n",
      "########## Iter 35 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 155969, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 12466, NNZ: 734\n",
      "bias            Iterations: 15, Total Push Operations: 14577, NNZ: 719\n",
      "lazy            Iterations: 21, Total Push Operations: 35831, NNZ: 722\n",
      "clipped         Iterations: 15, Total Push Operations: 12077, NNZ: 723\n",
      "\n",
      "########## Iter 36 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 157099, NNZ: 2485\n",
      "standard        Iterations: 14, Total Push Operations: 16501, NNZ: 1244\n",
      "bias            Iterations: 18, Total Push Operations: 19780, NNZ: 1182\n",
      "lazy            Iterations: 16, Total Push Operations: 41385, NNZ: 1192\n",
      "clipped         Iterations: 14, Total Push Operations: 16503, NNZ: 1248\n",
      "\n",
      "########## Iter 37 ##########\n",
      "power-iter      Iterations: 22, Total Push Operations: 178697, NNZ: 2485\n",
      "standard        Iterations: 18, Total Push Operations: 11871, NNZ: 914\n",
      "bias            Iterations: 20, Total Push Operations: 13816, NNZ: 863\n",
      "lazy            Iterations: 20, Total Push Operations: 29034, NNZ: 869\n",
      "clipped         Iterations: 18, Total Push Operations: 11821, NNZ: 912\n",
      "\n",
      "########## Iter 38 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 156677, NNZ: 2485\n",
      "standard        Iterations: 14, Total Push Operations: 12467, NNZ: 914\n",
      "bias            Iterations: 16, Total Push Operations: 14380, NNZ: 870\n",
      "lazy            Iterations: 17, Total Push Operations: 32193, NNZ: 872\n",
      "clipped         Iterations: 14, Total Push Operations: 12408, NNZ: 906\n",
      "\n",
      "########## Iter 39 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 161852, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 19353, NNZ: 1484\n",
      "bias            Iterations: 16, Total Push Operations: 23392, NNZ: 1445\n",
      "lazy            Iterations: 18, Total Push Operations: 50141, NNZ: 1451\n",
      "clipped         Iterations: 15, Total Push Operations: 19456, NNZ: 1473\n",
      "\n",
      "########## Iter 40 ##########\n",
      "power-iter      Iterations: 19, Total Push Operations: 139903, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 7524, NNZ: 590\n",
      "bias            Iterations: 17, Total Push Operations: 8881, NNZ: 573\n",
      "lazy            Iterations: 17, Total Push Operations: 21449, NNZ: 575\n",
      "clipped         Iterations: 15, Total Push Operations: 7524, NNZ: 590\n",
      "\n",
      "########## Iter 41 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 133429, NNZ: 2485\n",
      "standard        Iterations: 14, Total Push Operations: 2248, NNZ: 129\n",
      "bias            Iterations: 16, Total Push Operations: 2548, NNZ: 124\n",
      "lazy            Iterations: 16, Total Push Operations: 7667, NNZ: 124\n",
      "clipped         Iterations: 14, Total Push Operations: 2248, NNZ: 129\n",
      "\n",
      "########## Iter 42 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 150971, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 10526, NNZ: 896\n",
      "bias            Iterations: 16, Total Push Operations: 12406, NNZ: 864\n",
      "lazy            Iterations: 18, Total Push Operations: 26439, NNZ: 869\n",
      "clipped         Iterations: 16, Total Push Operations: 10526, NNZ: 896\n",
      "\n",
      "########## Iter 43 ##########\n",
      "power-iter      Iterations: 23, Total Push Operations: 165433, NNZ: 2485\n",
      "standard        Iterations: 19, Total Push Operations: 3326, NNZ: 227\n",
      "bias            Iterations: 20, Total Push Operations: 3907, NNZ: 214\n",
      "lazy            Iterations: 22, Total Push Operations: 8259, NNZ: 214\n",
      "clipped         Iterations: 19, Total Push Operations: 3306, NNZ: 226\n",
      "\n",
      "########## Iter 44 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 171759, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 25717, NNZ: 1689\n",
      "bias            Iterations: 15, Total Push Operations: 30381, NNZ: 1654\n",
      "lazy            Iterations: 16, Total Push Operations: 67898, NNZ: 1663\n",
      "clipped         Iterations: 15, Total Push Operations: 25771, NNZ: 1688\n",
      "\n",
      "########## Iter 45 ##########\n",
      "power-iter      Iterations: 22, Total Push Operations: 185477, NNZ: 2485\n",
      "standard        Iterations: 18, Total Push Operations: 16075, NNZ: 1254\n",
      "bias            Iterations: 19, Total Push Operations: 18663, NNZ: 1197\n",
      "lazy            Iterations: 20, Total Push Operations: 40074, NNZ: 1209\n",
      "clipped         Iterations: 18, Total Push Operations: 16018, NNZ: 1248\n",
      "\n",
      "########## Iter 46 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 157306, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 14666, NNZ: 996\n",
      "bias            Iterations: 17, Total Push Operations: 17391, NNZ: 966\n",
      "lazy            Iterations: 17, Total Push Operations: 37257, NNZ: 969\n",
      "clipped         Iterations: 15, Total Push Operations: 14206, NNZ: 975\n",
      "\n",
      "########## Iter 47 ##########\n",
      "power-iter      Iterations: 20, Total Push Operations: 145356, NNZ: 2485\n",
      "standard        Iterations: 17, Total Push Operations: 4006, NNZ: 283\n",
      "bias            Iterations: 18, Total Push Operations: 4434, NNZ: 273\n",
      "lazy            Iterations: 18, Total Push Operations: 11012, NNZ: 271\n",
      "clipped         Iterations: 17, Total Push Operations: 3986, NNZ: 282\n",
      "\n",
      "########## Iter 48 ##########\n",
      "power-iter      Iterations: 21, Total Push Operations: 171187, NNZ: 2485\n",
      "standard        Iterations: 16, Total Push Operations: 17803, NNZ: 1206\n",
      "bias            Iterations: 18, Total Push Operations: 20689, NNZ: 1175\n",
      "lazy            Iterations: 18, Total Push Operations: 48266, NNZ: 1184\n",
      "clipped         Iterations: 16, Total Push Operations: 17416, NNZ: 1192\n",
      "\n",
      "########## Iter 49 ##########\n",
      "power-iter      Iterations: 21, Total Push Operations: 154557, NNZ: 2485\n",
      "standard        Iterations: 19, Total Push Operations: 6325, NNZ: 562\n",
      "bias            Iterations: 19, Total Push Operations: 7828, NNZ: 542\n",
      "lazy            Iterations: 22, Total Push Operations: 15597, NNZ: 544\n",
      "clipped         Iterations: 19, Total Push Operations: 6325, NNZ: 562\n",
      "\n",
      "########## Iter 50 ##########\n",
      "power-iter      Iterations: 22, Total Push Operations: 177240, NNZ: 2485\n",
      "standard        Iterations: 15, Total Push Operations: 11963, NNZ: 831\n",
      "bias            Iterations: 15, Total Push Operations: 14362, NNZ: 798\n",
      "lazy            Iterations: 18, Total Push Operations: 29733, NNZ: 812\n",
      "clipped         Iterations: 15, Total Push Operations: 11657, NNZ: 820\n",
      "\n",
      "\n",
      "########## Results ##########\n",
      "Parameters: lazy_alpha=0.3, alpha=0.462, epsilon=1.0e-06, max_degree=150\n",
      "\n",
      "Avg Push Operations:\n",
      "\tpower-iter: 143801\n",
      "\tstandard: 10880\n",
      "\tbias: 12733\n",
      "\tlazy: 29162\n",
      "\tclipped: 10783\n",
      "\n",
      "Precision Top-100:\n",
      "\tstandard: 0.995\n",
      "\tbias: 0.992\n",
      "\tlazy: 0.993\n",
      "\tclipped: 0.987\n",
      "\n",
      "mean power-iter ppr:  3.693e-04\n",
      "Mean Absolute Error:\n",
      "\tstandard: 3.998e-07\n",
      "\tbias: 5.666e-07\n",
      "\tlazy: 5.375e-07\n",
      "\tclipped: 6.414e-07\n"
     ]
    }
   ],
   "source": [
    "lazy_alpha = 0.3\n",
    "alpha = (2 * lazy_alpha) / (1 + lazy_alpha)\n",
    "\n",
    "epsilon = 1e-6\n",
    "top_k = 100\n",
    "num_source = 50\n",
    "\n",
    "# Modify your test:\n",
    "test_list = ['standard', 'bias', 'lazy', 'clipped']\n",
    "\n",
    "def get_approx_ppr(key_, target_id_):\n",
    "    ppr_func_dict = {\n",
    "        'standard': standard_local_push_ppr,  # PPRGo, r_v = 0\n",
    "        'uniform': uniform_local_push_ppr,  # same as 'standard'\n",
    "        'batch': batch_local_push_ppr,  # update all source nodes simultaneously\n",
    "        'bias': standard_local_push_ppr,  # MAPPR, 0 < r_v < threshold\n",
    "        'lazy': standard_local_push_ppr,  # original local-push\n",
    "        'lazy-uniform': uniform_local_push_ppr,\n",
    "        'lazy-batch': batch_local_push_ppr,\n",
    "        'clipped': standard_local_push_ppr,  # 'standard' ppr on clipped graph\n",
    "        'clipped-lazy': standard_local_push_ppr,\n",
    "    }\n",
    "    g_ = g_sampled if 'clipped' in key_ else g\n",
    "    alpha_ = lazy_alpha if 'lazy' in key_ else alpha\n",
    "    beta_ = 0.5 if 'bias' in key_ else 0.\n",
    "    gamma_ = 0.5 if 'lazy' in key_ else 1.\n",
    "    return ppr_func_dict[key_](g_, target_id_, alpha_, epsilon, beta_, gamma_)\n",
    "\n",
    "total_base_p = 0.\n",
    "total_concur, total_err, total_push = defaultdict(int), defaultdict(float), defaultdict(int)\n",
    "\n",
    "source_nodes = torch.randperm(data.num_nodes)[:num_source]\n",
    "for i, target_id in enumerate(source_nodes):\n",
    "    print(f'\\n########## Iter {i+1} ##########')\n",
    "    base_p, base_num_push = power_iter_ppr(norm_adj_t, target_id, alpha, 1e-10, 100, unweighted_degree)\n",
    "\n",
    "    total_base_p += base_p\n",
    "    total_push['power-iter'] += base_num_push\n",
    "    _, base_top_k = torch.sort(base_p, descending=True)\n",
    "\n",
    "    for key in test_list:\n",
    "        approx_p, approx_num_iter, approx_num_push = get_approx_ppr(key, target_id)\n",
    "        print(f'{key:15s} Iterations: {approx_num_iter}, Total Push Operations: {approx_num_push}, NNZ: {sum(approx_p > 0)}')\n",
    "\n",
    "        total_push[key] += approx_num_push\n",
    "        total_err[key] += sum(abs(approx_p - base_p)).item()\n",
    "        _, approx_top_k = torch.sort(approx_p, descending=True)\n",
    "        total_concur[key] += np.intersect1d(base_top_k[:top_k], approx_top_k[:top_k]).shape[0]\n",
    "\n",
    "# print overall results\n",
    "print(f'\\n\\n########## Results ##########')\n",
    "print(f'Parameters: lazy_alpha={lazy_alpha}, alpha={alpha:.3f}, epsilon={epsilon:.1e}, max_degree={MAX_DEGREE}')\n",
    "\n",
    "print(f'\\nAvg Push Operations:')\n",
    "for k, v in total_push.items():\n",
    "    print(f'\\t{k}: {v/num_source:.0f}')\n",
    "\n",
    "print(f'\\nPrecision Top-{top_k}:')\n",
    "for k, v in total_concur.items():\n",
    "    print(f'\\t{k}: {v/(top_k * num_source):.3f}')\n",
    "\n",
    "print(f'\\nmean power-iter ppr: {total_base_p.mean().item()/num_source: .3e}'\n",
    "      f'\\nMean Absolute Error:')\n",
    "for k, v in total_err.items():\n",
    "    print(f'\\t{k}: {v/(data.num_nodes*num_source):.3e}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPRGO (close to C implementation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _calc_ppr_node(target_id_, indptr_, indices_, degree_, weights_, alpha_, epsilon_):\n",
    "    alpha_eps = alpha_ * epsilon_\n",
    "    f32_0 = 0.\n",
    "    p = {target_id_: f32_0}\n",
    "    r = {target_id_: alpha_}\n",
    "    q = [target_id_]\n",
    "    while len(q) > 0:\n",
    "        unode = q.pop()\n",
    "\n",
    "        res = r[unode] if unode in r else f32_0\n",
    "        if unode in p:\n",
    "            p[unode] += res\n",
    "        else:\n",
    "            p[unode] = res\n",
    "        r[unode] = f32_0\n",
    "        for vnode in indices_[indptr_[unode]:indptr_[unode + 1]]:\n",
    "            _val = (1 - alpha_) * res * weights_[unode] / degree_[unode]\n",
    "            if vnode in r:\n",
    "                r[vnode] += _val\n",
    "            else:\n",
    "                r[vnode] = _val\n",
    "\n",
    "            res_vnode = r[vnode] if vnode in r else f32_0\n",
    "            if res_vnode >= alpha_eps * degree_[vnode]:\n",
    "                if vnode not in q:\n",
    "                    q.append(vnode)\n",
    "\n",
    "    return list(p.keys()), list(p.values())\n",
    "\n",
    "# PPRGO Implementation, needs numba compiler acceleration\n",
    "# Root nodes level parallelization\n",
    "_calc_ppr_node(0, indptr.tolist(), indices.tolist(), degree.tolist(), value.tolist(), 0.15, 1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}