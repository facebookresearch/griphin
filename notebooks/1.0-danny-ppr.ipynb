{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 1,  1, 12, 13])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "t = torch.arange(10, 14)\n",
    "index = torch.tensor([True, True, False, False])\n",
    "t[index]= torch.tensor([1, 1])\n",
    "t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPR HOMEWORK"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p:  tensor([0., 0., 0.])  r:  tensor([0.5000, 0.0000, 0.0000])\n",
      "p:  tensor([0.5000, 0.0000, 0.0000])  r:  tensor([0.0000, 0.2500, 0.0000])\n",
      "p:  tensor([0.5000, 0.2500, 0.0000])  r:  tensor([0.0000, 0.0000, 0.1250])\n",
      "p:  tensor([0.5000, 0.2500, 0.1250])  r:  tensor([0.0625, 0.0000, 0.0000])\n",
      "p:  tensor([0.5625, 0.2500, 0.1250])  r:  tensor([0.0000, 0.0312, 0.0000])\n",
      "p:  tensor([0.5625, 0.2812, 0.1250])  r:  tensor([0.0000, 0.0000, 0.0156])\n",
      "p:  tensor([0.5625, 0.2812, 0.1406])  r:  tensor([0.0078, 0.0000, 0.0000])\n",
      "p:  tensor([0.5703, 0.2812, 0.1406])  r:  tensor([0.0000, 0.0039, 0.0000])\n",
      "p:  tensor([0.5703, 0.2852, 0.1406])  r:  tensor([0.0000, 0.0000, 0.0020])\n",
      "p:  tensor([0.5703, 0.2852, 0.1426])  r:  tensor([0.0010, 0.0000, 0.0000])\n",
      "p:  tensor([0.5713, 0.2852, 0.1426])  r:  tensor([0.0000, 0.0005, 0.0000])\n",
      "p:  tensor([0.5713, 0.2856, 0.1426])  r:  tensor([0.0000, 0.0000, 0.0002])\n",
      "p:  tensor([0.5713, 0.2856, 0.1428])  r:  tensor([0.0001, 0.0000, 0.0000])\n",
      "p:  tensor([0.5714, 0.2856, 0.1428])  r:  tensor([0.0000e+00, 6.1035e-05, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1428])  r:  tensor([0.0000e+00, 0.0000e+00, 3.0518e-05])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([1.5259e-05, 0.0000e+00, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([0.0000e+00, 7.6294e-06, 0.0000e+00])\n",
      "p:  tensor([0.5714, 0.2857, 0.1429])  r:  tensor([0.0000e+00, 0.0000e+00, 3.8147e-06])\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([0.5714, 0.2857, 0.1429])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indptr = torch.tensor([0, 1, 2, 3])\n",
    "indices = torch.tensor([1, 2, 0])\n",
    "degree = torch.tensor([1, 1, 1])\n",
    "g = (indptr, indices, degree)\n",
    "\n",
    "\n",
    "def approx_ppr(g_, a_, t_, e_):\n",
    "    indptr_, indices_, degree_ = g_\n",
    "    num_nodes = degree_.size(-1)\n",
    "\n",
    "    # initialize\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[t_] = a_\n",
    "\n",
    "    threshold = a_ * e_ * degree_\n",
    "    while True:\n",
    "        print('p: ', p, ' r: ', r)\n",
    "        mask = r > threshold\n",
    "        if mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # update\n",
    "        p[mask] += r[mask]\n",
    "        m = (1 - a_) * r[mask] / degree_[mask]\n",
    "        r[mask] = 0\n",
    "\n",
    "        # can be optimized by using scatter()\n",
    "        v_idx = mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            u_idx = indices_[indptr_[v]: indptr_[v+1]]\n",
    "            r[u_idx] += m[i]\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "ppr_score = approx_ppr(g, 0.5, 0, 1e-5)\n",
    "ppr_score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPR Experiments (power-iter vs local-push)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "from torch_geometric.datasets import Planetoid\n",
    "import torch_geometric.transforms as T\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def power_iter_ppr(P_w, target_id_, alpha_, epsilon_, max_iter, unweighted_degree_):\n",
    "    num_nodes = P_w.size(0)\n",
    "    s = torch.zeros(num_nodes)\n",
    "    s[target_id_] = 1\n",
    "    s = s.view(-1, 1)\n",
    "\n",
    "    x = s.clone()\n",
    "    num_push = 0\n",
    "    for i in range(max_iter):\n",
    "        x_last = x\n",
    "        x = alpha_ * s + (1 - alpha_) * (P_w @ x)\n",
    "        # total num of operations\n",
    "        x_last_nnz_index = x_last.view(-1).nonzero(as_tuple=False).view(-1)\n",
    "        num_push += unweighted_degree_[x_last_nnz_index].sum()\n",
    "        # check convergence, l1 norm\n",
    "        if (abs(x - x_last)).sum() < num_nodes * epsilon_:\n",
    "            print(f'power-iter      Iterations: {i}, Total Push Operations: {num_push.item()},'\n",
    "                  f' NNZ: {(x.view(-1) > 0).sum()}')\n",
    "            return x.view(-1), num_push.item()\n",
    "\n",
    "    print(f'Failed to converge with tolerance({epsilon_}) and iter({max_iter})')\n",
    "    return x.view(-1), num_push.item()\n",
    "\n",
    "\n",
    "def standard_local_push_ppr(g_, target_id_, alpha_, epsilon_, beta_=0., gamma_=1., max_degree_=-1, drop_coe_=0):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations = num_push = 0\n",
    "    num_affected_nodes = num_affected_edges = 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    drop_threshold = drop_coe_ * threshold\n",
    "    bias = beta_ * threshold\n",
    "\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        # if iterations == 15:\n",
    "        #     break\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # drop nodes below specific threshold\n",
    "        # print(((r < drop_threshold) & (r > 0)).sum().item())\n",
    "        r[(r < drop_threshold) & (r > 0)] = 0\n",
    "\n",
    "        v_idx = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "            num_degree = end - start\n",
    "            if max_degree_ == -1 or num_degree <= max_degree_:\n",
    "                ptr = torch.arange(start, end)\n",
    "            else:\n",
    "                ptr = torch.randperm(num_degree)[:max_degree_] + start\n",
    "                num_affected_nodes += 1\n",
    "                num_affected_edges += num_degree - max_degree_\n",
    "\n",
    "            u_idx = g_['indices'][ptr]\n",
    "            u_weights = g_['edge_weights'][ptr]\n",
    "\n",
    "            while r[v] > threshold[v]:\n",
    "                # update source node\n",
    "                if beta_ == 0:\n",
    "                    p[v] += alpha_ * r[v]\n",
    "                    m_v = (1 - alpha_) * gamma_ * r[v]\n",
    "                    r[v] = (1 - alpha_) * (1 - gamma_) * r[v]\n",
    "                else:\n",
    "                    p[v] += alpha_ * (r[v] - bias[v])\n",
    "                    m_v = (1 - alpha_) * (r[v] - bias[v])\n",
    "                    r[v] = bias[v]\n",
    "\n",
    "                # batch update neighbors\n",
    "                r[u_idx] += m_v * (u_weights / u_weights.sum())\n",
    "\n",
    "                num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return p, iterations, num_push.item(), num_affected_nodes, num_affected_edges\n",
    "\n",
    "\n",
    "def uniform_local_push_ppr(g_, target_id_, alpha_, epsilon_, gamma_=1.):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations, num_push = 0, 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        v_idx = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            # update source node\n",
    "            p[v] += alpha_ * r[v]\n",
    "            temp = (1 - alpha_) * r[v]\n",
    "            r[v] = (1 - gamma_) * temp\n",
    "            m_v = gamma_ * temp / g_['weighted_degree'][v]\n",
    "\n",
    "            # batch update neighbors\n",
    "            start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "            u_idx = g_['indices'][start: end]\n",
    "            u_weights = g_['edge_weights'][start: end]\n",
    "            r[u_idx] += m_v * u_weights\n",
    "\n",
    "            num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    return p, iterations, num_push.item(), 0, 0\n",
    "\n",
    "\n",
    "def batch_local_push_ppr(g_, target_id_, alpha_, epsilon_, gamma_=1., max_degree_=-1, drop_coe_=0):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    iterations = num_push = 0\n",
    "    num_affected_nodes = num_affected_edges = 0\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    drop_threshold = drop_coe_ * threshold\n",
    "\n",
    "    num_p = 0\n",
    "\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # drop nodes below specific threshold\n",
    "        r[(r < drop_threshold) & (r > 0)] = 0\n",
    "\n",
    "        v_idx_ = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        # while True:\n",
    "        #     v_mask_ = r[v_idx] > threshold[v_idx]\n",
    "        #     if v_mask_.sum() == 0:\n",
    "        #         break\n",
    "        #     v_idx_ = v_idx[v_mask_]\n",
    "\n",
    "        # print(v_idx_.numel())\n",
    "        num_p += v_idx_.numel()\n",
    "\n",
    "        # batch update source nodes\n",
    "        p[v_idx_] += alpha_ * r[v_idx_]\n",
    "        m = (1 - alpha_) * r[v_idx_]\n",
    "        r[v_idx_] = (1 - gamma_) * m\n",
    "        m = gamma_ * m\n",
    "\n",
    "        for i, v in enumerate(v_idx_):\n",
    "            start, end =  g_['indptr'][v], g_['indptr'][v+1]\n",
    "            num_degree = end - start\n",
    "            if max_degree_ == -1 or num_degree <= max_degree_:\n",
    "                ptr = torch.arange(start, end)\n",
    "            else:\n",
    "                ptr = torch.randperm(num_degree)[:max_degree_] + start\n",
    "                num_affected_nodes += 1\n",
    "                num_affected_edges += num_degree - max_degree_\n",
    "            # batch update neighbors\n",
    "            u_idx = g_['indices'][ptr]\n",
    "            u_weights = g_['edge_weights'][ptr]\n",
    "            r[u_idx] += m[i] * u_weights / u_weights.sum()\n",
    "\n",
    "            num_push += end - start\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "    print('Total Num P', num_p)\n",
    "    return p, iterations, num_push.item(), num_affected_nodes, num_affected_edges"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "({'indptr': tensor([        0,       174,       263,  ..., 123718233, 123718242,\n          123718280]),\n  'indices': tensor([    384,    2412,    7554,  ..., 1787657, 1864057, 2430488]),\n  'edge_weights': tensor([0.8107, 0.1535, 0.7825,  ..., 0.8139, 0.9815, 0.1251]),\n  'weighted_degree': tensor([84.9130, 48.3407, 16.8389,  ..., 27.0977,  4.8304, 20.9754])},\n SparseTensor(row=tensor([      0,       0,       0,  ..., 2449028, 2449028, 2449028]),\n              col=tensor([    384,    2412,    7554,  ..., 1787657, 1864057, 2430488]),\n              val=tensor([0.0343, 0.0047, 0.0039,  ..., 0.0106, 0.0138, 0.0709]),\n              size=(2449029, 2449029), nnz=123718280, density=0.00%))"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ogb.nodeproppred import PygNodePropPredDataset\n",
    "\n",
    "\"\"\"Graph Loading\"\"\"\n",
    "dataset = PygNodePropPredDataset(name='ogbn-products', root='/data/gangda/ogb', transform=T.ToSparseTensor())\n",
    "# dataset = Planetoid(root='/data/gangda/pyg', name='Cora', pre_transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "unweighted_degree = data.adj_t.sum(dim=0).to(torch.int)\n",
    "coo_adj_edge_weight = torch.rand(data.num_edges)\n",
    "# coo_adj_edge_weight = torch.ones(data.num_edges)\n",
    "data.adj_t.set_value_(coo_adj_edge_weight, layout='csc')\n",
    "\n",
    "# local-push\n",
    "indptr, indices, value = data.adj_t.csc()\n",
    "degree = data.adj_t.sum(dim=0).to(torch.float)\n",
    "g = {\n",
    "    'indptr': indptr,\n",
    "    'indices': indices,\n",
    "    'edge_weights': value,\n",
    "    'weighted_degree': degree,\n",
    "}\n",
    "\n",
    "# power-iteration\n",
    "norm_adj_t = data.adj_t * degree.pow(-1).view(1, -1)\n",
    "\n",
    "g, norm_adj_t"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nodes affected ratio of different max degree\n",
    "- 1000 0.1%\n",
    "- 350 1%\n",
    "- 200 3%\n",
    "- 150 6%\n",
    "- 100 12%\n",
    "- 80 18%\n",
    "- 60 24%\n",
    "- 50 30%"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1142,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.2585)"
     },
     "execution_count": 1142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(unweighted_degree > 60).sum() / data.num_nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "outputs": [
    {
     "data": {
      "text/plain": "{'indptr': tensor([    0,     3,     6,  ..., 10530, 10534, 10538]),\n 'indices': tensor([ 633, 1862, 2582,  ...,  598, 1473, 2706]),\n 'edge_weights': tensor([0.2110, 0.0817, 0.7195,  ..., 0.5115, 0.7540, 0.7701]),\n 'weighted_degree': tensor([1.0122, 0.9240, 2.2092,  ..., 0.2975, 2.3681, 2.1038])}"
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Deprecated Sampling\"\"\"\n",
    "# sampled local-push\n",
    "adj = data.adj_t.t()\n",
    "adj = adj.sample_adj(torch.arange(data.num_nodes), 150, replace=False)[0]\n",
    "_indptr, _indices, _value = adj.csr()\n",
    "_degree = adj.sum(dim=1).to(torch.float)\n",
    "g_sampled = {\n",
    "    'indptr': _indptr,\n",
    "    'indices': _indices,\n",
    "    'edge_weights': _value,\n",
    "    'weighted_degree': _degree,\n",
    "}\n",
    "g_sampled"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "########## Iter 1 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 699958434, NNZ: 2338909\n",
      "standard        Iterations: 9, Total Push Operations: 191441, NNZ: 2690, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 5157\n",
      "batch           Iterations: 20, Total Push Operations: 245324, NNZ: 2663, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 2 ##########\n",
      "power-iter      Iterations: 10, Total Push Operations: 779120479, NNZ: 2338909\n",
      "standard        Iterations: 11, Total Push Operations: 116896, NNZ: 1738, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 4539\n",
      "batch           Iterations: 12, Total Push Operations: 154494, NNZ: 1735, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 3 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 718832620, NNZ: 2338909\n",
      "standard        Iterations: 8, Total Push Operations: 160632, NNZ: 2042, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 3188\n",
      "batch           Iterations: 10, Total Push Operations: 175921, NNZ: 2015, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 4 ##########\n",
      "power-iter      Iterations: 10, Total Push Operations: 703292415, NNZ: 2333489\n",
      "standard        Iterations: 9, Total Push Operations: 71133, NNZ: 1107, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 1949\n",
      "batch           Iterations: 12, Total Push Operations: 82135, NNZ: 1087, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 5 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 575757656, NNZ: 2329848\n",
      "standard        Iterations: 9, Total Push Operations: 140068, NNZ: 3015, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 5754\n",
      "batch           Iterations: 12, Total Push Operations: 180595, NNZ: 2974, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 6 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 677345758, NNZ: 2333488\n",
      "standard        Iterations: 9, Total Push Operations: 194563, NNZ: 3105, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 3533\n",
      "batch           Iterations: 10, Total Push Operations: 198834, NNZ: 3067, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 7 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 685318254, NNZ: 2333489\n",
      "standard        Iterations: 8, Total Push Operations: 174072, NNZ: 3456, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 3986\n",
      "batch           Iterations: 10, Total Push Operations: 179258, NNZ: 3401, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 8 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 667920501, NNZ: 2333487\n",
      "standard        Iterations: 10, Total Push Operations: 240304, NNZ: 1223, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 3059\n",
      "batch           Iterations: 12, Total Push Operations: 336222, NNZ: 1222, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 9 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 597469262, NNZ: 2329846\n",
      "standard        Iterations: 9, Total Push Operations: 185050, NNZ: 1325, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 2529\n",
      "batch           Iterations: 14, Total Push Operations: 231847, NNZ: 1316, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "########## Iter 10 ##########\n",
      "power-iter      Iterations: 9, Total Push Operations: 684911635, NNZ: 2338906\n",
      "standard        Iterations: 9, Total Push Operations: 229930, NNZ: 2163, Clipped Nodes(Edges): 0(0)\n",
      "Total Num P 3408\n",
      "batch           Iterations: 11, Total Push Operations: 270003, NNZ: 2130, Clipped Nodes(Edges): 0(0)\n",
      "\n",
      "\n",
      "########## Results ##########\n",
      "Parameters: lazy_alpha=0.3, alpha=0.462, epsilon=1.0e-06, max_degree=1000, drop_coe=0.8\n",
      "\n",
      "Avg Push Operations:\n",
      "\tpower-iter: 678992701\n",
      "\tstandard: 170409\n",
      "\tbatch: 205463\n",
      "\n",
      "Avg Clipped Nodes(Edges):\n",
      "\tstandard: 0(0)\n",
      "\tbatch: 0(0)\n",
      "\n",
      "Precision Top-100:\n",
      "\tstandard: 0.961\n",
      "\tbatch: 0.961\n",
      "\n",
      "mean power-iter ppr:  4.083e-07\n",
      "Mean Absolute Error:\n",
      "\tstandard: 4.040e-08\n",
      "\tbatch: 4.162e-08\n",
      "\n",
      "Avg Run Time:\n",
      "\tpower-iter: 1.667s\n",
      "\tstandard: 1.283s\n",
      "\tbatch: 1.466s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "\"\"\"Testing\"\"\"\n",
    "lazy_alpha = 0.3\n",
    "alpha = (2 * lazy_alpha) / (1 + lazy_alpha)\n",
    "epsilon = 1e-6\n",
    "\n",
    "max_degree = 1000\n",
    "drop_coe = 0.8\n",
    "\n",
    "top_k = 100\n",
    "num_source = 10\n",
    "\n",
    "# Modify your test:\n",
    "test_list = ['standard', 'batch']\n",
    "\n",
    "def get_approx_ppr(key_, target_id_):\n",
    "    ppr_func_dict = {\n",
    "        'standard': standard_local_push_ppr,  # PPRGo, r_v = 0\n",
    "        'uniform': uniform_local_push_ppr,  # same as 'standard'\n",
    "        'batch': batch_local_push_ppr,  # update all source nodes simultaneously\n",
    "        'bias': standard_local_push_ppr,  # MAPPR, 0 < r_v < threshold\n",
    "        'lazy': standard_local_push_ppr,  # original local-push\n",
    "        'lazy-uniform': uniform_local_push_ppr,\n",
    "        'lazy-batch': batch_local_push_ppr,\n",
    "        'clipped': standard_local_push_ppr,  # 'standard' ppr on clipped graph\n",
    "        'clipped-lazy': standard_local_push_ppr,\n",
    "        'clipped-batch': batch_local_push_ppr,\n",
    "        'drop': standard_local_push_ppr,\n",
    "        'drop-batch': batch_local_push_ppr,\n",
    "    }\n",
    "    kwargs = {\n",
    "        'alpha_': lazy_alpha if 'lazy' in key_ else alpha,\n",
    "        'gamma_': 0.5 if 'lazy' in key_ else 1.,\n",
    "        'epsilon_': epsilon,\n",
    "    }\n",
    "    if 'bias' in key_:\n",
    "        kwargs['beta_'] = 0.5\n",
    "    if 'clipped' in key_:\n",
    "        kwargs['max_degree_'] = max_degree\n",
    "    if 'drop' in key_:\n",
    "        kwargs['drop_coe_'] = drop_coe\n",
    "    return ppr_func_dict[key_](g, target_id_, **kwargs)\n",
    "\n",
    "total_base_p = 0.\n",
    "total_concur, total_err, total_push = defaultdict(int), defaultdict(float), defaultdict(int)\n",
    "total_clipped_nodes, total_clipped_edges = defaultdict(int), defaultdict(int)\n",
    "total_time = defaultdict(float)\n",
    "\n",
    "source_nodes = torch.randperm(data.num_nodes)[:num_source]\n",
    "for epoch, target_id in enumerate(source_nodes):\n",
    "    print(f'\\n########## Iter {epoch+1} ##########')\n",
    "\n",
    "    tik = time.time()\n",
    "    base_p, base_num_push = power_iter_ppr(norm_adj_t, target_id, alpha, 1e-10, 100, unweighted_degree)\n",
    "    total_time['power-iter'] += time.time() - tik\n",
    "\n",
    "    total_base_p += base_p\n",
    "    total_push['power-iter'] += base_num_push\n",
    "    _, base_top_k = torch.sort(base_p, descending=True)\n",
    "\n",
    "    for key in test_list:\n",
    "        tik = time.time()\n",
    "        approx_p, approx_num_iter, approx_num_push, num_clipped_nodes, num_clipped_edges = get_approx_ppr(key, target_id)\n",
    "        total_time[key] += time.time() - tik\n",
    "\n",
    "        print(f'{key:15s} Iterations: {approx_num_iter}, Total Push Operations: {approx_num_push}, NNZ: {(approx_p > 0).sum()}, Clipped Nodes(Edges): {num_clipped_nodes}({num_clipped_edges})')\n",
    "\n",
    "        total_push[key] += approx_num_push\n",
    "        total_err[key] += (abs(approx_p - base_p)).sum().item()\n",
    "        _, approx_top_k = torch.sort(approx_p, descending=True)\n",
    "        total_concur[key] += np.intersect1d(base_top_k[:top_k], approx_top_k[:top_k]).shape[0]\n",
    "\n",
    "        total_clipped_nodes[key] += num_clipped_nodes\n",
    "        total_clipped_edges[key] += num_clipped_edges\n",
    "\n",
    "# print overall results\n",
    "print(f'\\n\\n########## Results ##########')\n",
    "print(f'Parameters: lazy_alpha={lazy_alpha}, alpha={alpha:.3f}, epsilon={epsilon:.1e}, max_degree={max_degree}, drop_coe={drop_coe}')\n",
    "\n",
    "print(f'\\nAvg Push Operations:')\n",
    "for k, val in total_push.items():\n",
    "    print(f'\\t{k}: {val/num_source:.0f}')\n",
    "\n",
    "print(f'\\nAvg Clipped Nodes(Edges):')\n",
    "for k, val in total_clipped_nodes.items():\n",
    "    print(f'\\t{k}: {val/num_source:.0f}({total_clipped_edges[k]/num_source:.0f})')\n",
    "\n",
    "print(f'\\nPrecision Top-{top_k}:')\n",
    "for k, val in total_concur.items():\n",
    "    print(f'\\t{k}: {val/(top_k * num_source):.3f}')\n",
    "\n",
    "print(f'\\nmean power-iter ppr: {total_base_p.mean().item()/num_source: .3e}'\n",
    "      f'\\nMean Absolute Error:')\n",
    "for k, val in total_err.items():\n",
    "    print(f'\\t{k}: {val/(data.num_nodes*num_source):.3e}')\n",
    "\n",
    "print(f'\\nAvg Run Time:')\n",
    "for k, val in total_time.items():\n",
    "    print(f'\\t{k}: {val/num_source:.3f}s')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PPRGO (close to C implementation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def _calc_ppr_node(target_id_, indptr_, indices_, degree_, weights_, alpha_, epsilon_):\n",
    "    alpha_eps = alpha_ * epsilon_\n",
    "    f32_0 = 0.\n",
    "    p = {target_id_: f32_0}\n",
    "    r = {target_id_: alpha_}\n",
    "    q = [target_id_]\n",
    "    while len(q) > 0:\n",
    "        unode = q.pop()\n",
    "\n",
    "        res = r[unode] if unode in r else f32_0\n",
    "        if unode in p:\n",
    "            p[unode] += res\n",
    "        else:\n",
    "            p[unode] = res\n",
    "        r[unode] = f32_0\n",
    "        for vnode in indices_[indptr_[unode]:indptr_[unode + 1]]:\n",
    "            _val = (1 - alpha_) * res * weights_[unode] / degree_[unode]\n",
    "            if vnode in r:\n",
    "                r[vnode] += _val\n",
    "            else:\n",
    "                r[vnode] = _val\n",
    "\n",
    "            res_vnode = r[vnode] if vnode in r else f32_0\n",
    "            if res_vnode >= alpha_eps * degree_[vnode]:\n",
    "                if vnode not in q:\n",
    "                    q.append(vnode)\n",
    "\n",
    "    return list(p.keys()), list(p.values())\n",
    "\n",
    "# PPRGO Implementation, needs numba compiler acceleration\n",
    "# Root nodes level parallelization\n",
    "_calc_ppr_node(0, indptr.tolist(), indices.tolist(), degree.tolist(), value.tolist(), 0.15, 1e-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def local_push_ppr(g_, target_id_, alpha_, epsilon_, max_degree_=-1, drop_coe_=0.5):\n",
    "    num_nodes = g_['weighted_degree'].size(-1)\n",
    "    p = torch.zeros(num_nodes)\n",
    "    r = torch.zeros(num_nodes)\n",
    "    r[target_id_] = 1\n",
    "\n",
    "    threshold = epsilon_ * g_['weighted_degree']\n",
    "    drop_threshold = drop_coe_ * threshold\n",
    "\n",
    "    while True:\n",
    "        v_mask = r > threshold\n",
    "        if v_mask.sum() == 0:\n",
    "            break\n",
    "\n",
    "        # drop nodes below specific threshold\n",
    "        r[(r < drop_threshold) & (r > 0)] = 0\n",
    "\n",
    "        v_idx = v_mask.nonzero(as_tuple=False).view(-1)\n",
    "        for i, v in enumerate(v_idx):\n",
    "            start, end = g_['indptr'][v], g_['indptr'][v + 1]\n",
    "            num_degree = end - start\n",
    "            if max_degree_ == -1 or num_degree <= max_degree_:\n",
    "                ptr = torch.arange(start, end)\n",
    "            else:\n",
    "                ptr = torch.randperm(num_degree)[:max_degree_] + start\n",
    "\n",
    "            u_idx = g_['indices'][ptr]\n",
    "            u_weights = g_['edge_wewights'][ptr]\n",
    "\n",
    "            # update source node\n",
    "            p[v] += alpha_ * r[v]\n",
    "            m_v = (1 - alpha_) * r[v]\n",
    "            r[v] = 0\n",
    "            # batch update neighbors\n",
    "            r[u_idx] += m_v * (u_weights / u_weights.sum())\n",
    "\n",
    "    return p"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
